Sensors
-------
Retina
  Input modality: camera frames
  Model: CLIP-ViT-B/32
  Output modality: 512-dim vision embeddings
  Fed into: Occipital Lobe -> Thalamus

Cochlea
  Input modality: microphone audio
  Model: Whisper-small
  Output modality: audio embeddings
  Fed into: Auditory Cortex -> Thalamus

Early Processing
----------------
Occipital Lobe
  Input modality: visual embeddings from Retina
  Model: simple MLP
  Output modality: 128-dim visual features
  Fed into: Thalamus

Auditory Cortex
  Input modality: Whisper embeddings from Cochlea
  Model: simple MLP/Conv network
  Output modality: 128-dim auditory features
  Fed into: Thalamus

Thalamus
  Input modality: vision features, audio features, intero signals
  Model: gating relay
  Output modality: latest sample per modality
  Fed into: Default Mode Network (DMN)

Default Mode Network (DMN)
  Input modality: fused vision, audio, intero embeddings
  Model: custom Transformer/MLP (semantic hub)
  Output modality: 768-dim context embedding
  Fed into: Context Cortex, Salience Cortex, Hippocampus, Basal Ganglia, Motor Cortex

Context Cortex
  Input modality: context embeddings from DMN
  Model: GRU
  Output modality: temporal context embedding
  Fed into: Hippocampus and DMN (loop)

Salience Cortex
  Input modality: fused embedding from DMN
  Model: MLP
  Output modality: salience score
  Fed into: Reticular Activating System (RAS) and Hypothalamus/Pituitary Axis (HPA)

Hippocampus
  Input modality: multiple modality embeddings from DMN and Cortex modules
  Model: episodic memory index
  Output modality: recalled embeddings
  Fed into: Thalamus for replay (loop)

Basal Ganglia
  Input modality: context from DMN
  Model: gating MLP
  Output modality: go/no-go signal
  Fed into: Motor Cortex

Reticular Activating System (RAS)
  Input modality: salience scores
  Model: threshold switch
  Output modality: arousal level
  Fed into: Thalamus gating

Hypothalamus/Pituitary Axis (HPA)
  Input modality: novelty and error signals
  Model: hormone state machine
  Output modality: dopamine, norepinephrine, serotonin, acetylcholine levels
  Fed into: Trainer and DMN modulation

Language Areas
--------------
Wernicke's Area
  Input modality: text tokens
  Model: front half of GPT-2
  Output modality: semantic embeddings
  Fed into: DMN

Broca's Area
  Input modality: context embeddings from Motor Cortex
  Model: GPT-2 LM head
  Output modality: text tokens
  Fed into: environment / Motor Cortex output

Motor Cortex
  Input modality: context embeddings from DMN
  Model: GPT-2 back half with LoRA adapters
  Output modality: generated text and embeddings
  Fed into: Wernicke's Area (loop via re-embedding) and Thalamus as interoceptive feedback

Trainer
  Input modality: activations from DMN
  Model: Hebbian update logic
  Output modality: updated adapter weights
  Fed into: all modules with LoRA adapters

Loops
-----
- Motor Cortex text is re-encoded by Wernicke's Area and fed back through Thalamus to DMN, creating a feedback loop for executive reaction.
- Hippocampus recalls episodic embeddings and submits them to Thalamus, allowing recursive context updates.
- Context Cortex feeds temporal embeddings back into DMN for ongoing context accumulation.
- RAS adjusts Thalamic gating so processing becomes reactive to salience.

Bootstrapping Models
--------------------
- Vision: clip-vit-base-patch32
- Audio: whisper-small
- LLM Core: gpt2 (split front/back)
- Fusion & Cortex Experts: custom transformer/MLP
- Adapters: LoRA via peft

